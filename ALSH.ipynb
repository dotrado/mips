{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "ALSH_MIPS l2 TEST:\n",
      "L\tk\tPrecision\trecall\tALSH time\tLinear time\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "global name 'metric' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-fff06ec06895>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0mtest_dp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_r\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m     \u001b[0mlsh_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_neighbours\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-20-fff06ec06895>\u001b[0m in \u001b[0;36mlsh_test\u001b[0;34m(train_dp, test_dp, rand_num, num_neighbours, mips)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0;34m'l_vec'\u001b[0m\u001b[0;34m:\u001b[0m     \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m             }\n\u001b[0;32m--> 221\u001b[0;31m     \u001b[0mtester\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \"\"\"\n",
      "\u001b[0;32m<ipython-input-20-fff06ec06895>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, type, k_vec, l_vec)\u001b[0m\n\u001b[1;32m    194\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhits\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mext_test_dp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexact_hits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                     \u001b[0mlsh_hits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mix\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdist\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlsh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_neighbours\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                     \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorrect\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlsh_hits\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mhits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                     \u001b[0mnum_query\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: global name 'metric' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from operator import itemgetter\n",
    "from collections import defaultdict\n",
    "from abc import ABCMeta, abstractmethod\n",
    "import time\n",
    "U_global = 0.83\n",
    "\n",
    "class Hash:\n",
    "    __metaclass__ = ABCMeta\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def hash(self, vec):\n",
    "        print \"Hash.hash()\"\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def distance(u, v):\n",
    "        print \"Hash.distance()\"\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def combine(hashes):\n",
    "        return str(hashes)\n",
    "\n",
    "    \n",
    "class L2Lsh(Hash):\n",
    "    def __init__(self, r, d):\n",
    "        self.r, self.d = r, d\n",
    "        self.b = random.uniform(0, self.r)      # 0 < b < r\n",
    "        self.Data = [random.gauss(0, 1) for i in xrange(self.d)]\n",
    "\n",
    "    def hash(self, vec):\t# hash family\n",
    "        return int((np.dot(vec, self.Data) + self.b) / self.r)\n",
    "\n",
    "    @staticmethod\n",
    "    def distance(u, v):\n",
    "        return sum((ux - vx)**2 for ux, vx in zip(u, v))**0.5\n",
    "\n",
    "class Lshfunctions:\n",
    "    'LSH Wrapper'\n",
    "\n",
    "    def __init__(self, lsh_type, d, r = 2.5, k = 2, L = 2):\n",
    "        self.type = lsh_type\n",
    "        self.d, self.r, self.k, self.L, self.hash_tables = d, r, k, 0, []\n",
    "        self.resize(L)\n",
    "\n",
    "    def __get_hash_class__(self):\n",
    "        return L2Lsh\n",
    "\n",
    "    def create_hash_table(self):\n",
    "        return L2Lsh(self.r, self.d)\n",
    "\n",
    "    def resize(self, L):\n",
    "        if L < self.L:\n",
    "            self.hash_tables = self.hash_tables[:L]\n",
    "        else:\n",
    "            hash_funcs = [[self.create_hash_table() for h in xrange(self.k)] for l in xrange(self.L, L)]\n",
    "            self.hash_tables.extend([(g, defaultdict(lambda:[])) for g in hash_funcs])\n",
    "        self.L = L\n",
    "\n",
    "    def hash(self, ht, data):\n",
    "        return self.__get_hash_class__().combine([h.hash(data) for h in ht])\n",
    "\n",
    "    def index(self, train_dp):\n",
    "        self.train_dp = train_dp\n",
    "        for ht, ct in self.hash_tables:\n",
    "            for ix, p in enumerate(self.train_dp):\n",
    "                ct[self.hash(ht, p)].append(ix)\n",
    "        self.tot_touched = 0\n",
    "        self.num_test_dp = 0\n",
    "\n",
    "    def query(self, q, metric, max_results = 1):\n",
    "        if 0 == max_results:\n",
    "            max_results = 1\n",
    "        candidates = set()\n",
    "        for ht, ct in self.hash_tables:\n",
    "            matches = ct.get(self.hash(ht, q), [])\n",
    "            candidates.update(matches)\n",
    "        self.tot_touched += len(candidates)\n",
    "        self.num_test_dp += 1\n",
    "        candidates = [(ix, metric(q, self.train_dp[ix])) for ix in candidates]\n",
    "        candidates.sort(key=itemgetter(1))\n",
    "        return candidates[:max_results]\n",
    "\n",
    "    def get_avg_touched(self):\n",
    "        return self.tot_touched / self.num_test_dp\n",
    "\n",
    "    def distance(self, u, v):\n",
    "        return __get_hash_class__.distance(u, v)\n",
    "\n",
    "    \n",
    "    \n",
    "class L2LSH():\n",
    "    def __init__(self, train_dp, test_dp, r_values = 2.5, num_neighbours = 1):\n",
    "        kdata, qdata = len(train_dp[0]), len(test_dp[0])\n",
    "        self.d = kdata\n",
    "        self.train_dp = train_dp\n",
    "        self.test_dp = test_dp\n",
    "        self.r_values = r_values\n",
    "        self.q_num = len(self.test_dp)\n",
    "        self.num_neighbours = num_neighbours\n",
    "\n",
    "    def linear(self, q, metric, max_results):\n",
    "        candidates = [(ix, metric(q, p)) for ix, p in enumerate(self.train_dp)]\n",
    "        temp = sorted(candidates, key=itemgetter(1))\n",
    "        temp=temp[:max_results]\n",
    "        return temp\n",
    "\n",
    "    def run(self, type, k_vec = [2], l_vec = [2]):\n",
    "        if 'l2' == type:\n",
    "            metric = L2Lsh.distance\n",
    "        exact_hits = [[ix for ix, dist in self.linear(q, metric, self.num_neighbours)] for q in self.test_dp]   #exact_hits是距离q最近的那些点（这是真的，精准的）\n",
    "        for k in k_vec:\n",
    "            lsh = Lshfunctions(type, self.d, self.r_values, k, 0)\n",
    "\n",
    "            for L in l_vec:\n",
    "                lsh.resize(L)\n",
    "                lsh.index(self.train_dp)\n",
    "                correct = 0\n",
    "                num_query = 0\n",
    "                recall = 0\n",
    "                precision = 0\n",
    "                noZeroCount = np.count_nonzero(self.test_dp)\n",
    "                for q, hits in zip(self.test_dp, exact_hits):                   \n",
    "                    lsh_hits = [ix for ix, dist in lsh.query(q, metric, self.num_neighbours)]\n",
    "                    correct += int(lsh_hits == hits)\n",
    "                    num_query+=1\n",
    "                    recall += (float)(correct)/self.num_neighbours\n",
    "                    precision += (float)(correct)/noZeroCount\n",
    "                    correct = 0\n",
    "                recall/=num_query\n",
    "                precision/=num_query\n",
    "                print \"{0}\\t{1}\\t{2}\\t{3}\".format(L, k, float(precision), float(recall))\n",
    "\n",
    "class ALSH_MIPS(L2LSH):\n",
    "    'L2-ALSH for MIPS Test parameters'\n",
    "\n",
    "    def __init__(self, train_dp, test_dp, r_values = 2.5, num_neighbours = 1, m = 3):\n",
    "        kdata = len(train_dp[0])\n",
    "        qdata = len(test_dp[0])\n",
    "        self.m = m\n",
    "        self.half_extend = [0.5 for i in xrange(self.m)]\n",
    "        self.origin_train_dp = train_dp\n",
    "        self.origin_test_dp = test_dp\n",
    "        self.q_num = len(self.origin_test_dp)\n",
    "        dmax_norm = max([math.sqrt(np.dot(dd, dd)) for dd in train_dp])\n",
    "        dratio = float(U_global / dmax_norm)\n",
    "        self.norm_train_dp = [[dratio * dx for dx in dd] for dd in self.origin_train_dp]\n",
    "        norm_test_dp = []\n",
    "        for qv in self.origin_test_dp:\n",
    "            norm = math.sqrt(np.dot(qv, qv))\n",
    "            ratio = float(U_global / norm)\n",
    "            norm_test_dp.append([ratio * qx for qx in qv])\n",
    "        \n",
    "        self.norm_test_dp = norm_test_dp\n",
    "        self.ext_train_dp = [(dv + [np.dot(dv, dv)**(i+1) for i in xrange(self.m)] + [0.5 for i in xrange(self.m)]) for dv in self.norm_train_dp]\n",
    "        self.ext_test_dp = [(qv + [0.5 for i in xrange(self.m)] + [np.dot(qv, qv)**(i+1) for i in xrange(self.m)]) for qv in self.norm_test_dp]\n",
    "        new_len = kdata + 2 * m\n",
    "        L2LSH.__init__(self, self.ext_train_dp, self.ext_test_dp, r_values, num_neighbours)\n",
    "\n",
    "    # MIPS\n",
    "    def linear(self, q, metric, max_results):\n",
    "        candidates = [(ix, np.dot(q, p)) for ix, p in enumerate(self.origin_train_dp)]\n",
    "        temp = sorted(candidates, key=itemgetter(1), reverse=True)\n",
    "        temp=temp[:max_results]\n",
    "        return temp\n",
    "\n",
    "    def run(self, type, k_vec = [2], l_vec = [2]):\n",
    "        validate_metric, compute_metric = np.dot, L2Lsh.distance\n",
    "        start = time.time()\n",
    "        exact_hits = [[ix for ix, dist in self.linear(q, compute_metric, self.num_neighbours)] for q in self.origin_test_dp]\n",
    "        exact_hits = [[ix for ix, dist in self.linear(q, validate_metric, self.num_neighbours)] for q in self.origin_test_dp]\n",
    "        linear_time = time.time() - start\n",
    "        print 'ALSH_MIPS ' + type + ' TEST:'\n",
    "        print 'L\\tk\\tPrecision\\trecall\\tALSH time\\tLinear time'\n",
    "\n",
    "        for k in k_vec:\n",
    "            lsh = Lshfunctions(type, self.d, self.r_values, k, 0)\n",
    "            for L in l_vec:\n",
    "                lsh.resize(L)\n",
    "                lsh.index(self.ext_train_dp)\n",
    "                correct = 0\n",
    "                num_query = 0\n",
    "                recall = 0\n",
    "                precision = 0\n",
    "                noZeroCount = np.count_nonzero(self.ext_test_dp)\n",
    "                start = time.time()\n",
    "                for q, hits in zip(self.ext_test_dp, exact_hits):\n",
    "                    lsh_hits = [ix for ix, dist in lsh.query(q, metric, self.num_neighbours)]\n",
    "                    correct = correct + int(lsh_hits == hits)\n",
    "                    num_query+=1\n",
    "                    recall += (float)(correct)/self.num_neighbours\n",
    "                    precision += (float)(correct)/noZeroCount\n",
    "                    correct = 0\n",
    "                recall/=num_query\n",
    "                precision/=num_query\n",
    "                alsh_time = time.time() - start\n",
    "                \n",
    "                print \"{0}\\t{1}\\t{2}\\t{3}\\t\\t{4}\\t\\t{5}\".format(L, k, float(precision), float(recall), alsh_time, linear_time)\n",
    "    \n",
    "    @staticmethod\n",
    "    def RunOnParams(type, train_dp, test_dp, rand_num, num_neighbours):\n",
    "        return ALSH_MIPS(train_dp, test_dp, rand_num, num_neighbours)\n",
    "\n",
    "def lsh_test(train_dp, test_dp, rand_num, num_neighbours, mips = False):\n",
    "\n",
    "    type = 'l2'\n",
    "    tester = ALSH_MIPS.RunOnParams(type, train_dp, test_dp, rand_num, num_neighbours)\n",
    "    args = {\n",
    "                'type':      type,\n",
    "                'k_vec':     [1, 2, 4, 8],\n",
    "                'l_vec':     [2, 4, 8, 16, 32]\n",
    "            }\n",
    "    tester.run(**args)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    type = 'cosine'\n",
    "    tester = L2LSH.RunOnParams(type, mips, train_dp, test_dp, rand_num, num_neighbours)\n",
    "\n",
    "    args = {\n",
    "                'type':      type,\n",
    "                'k_vec':    [1, 2, 4, 8],\n",
    "                'l_vec':    [2, 4, 8, 16, 32]\n",
    "            }\n",
    "    tester.run(**args)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_dpet = \"../datasets\" + os.path.sep + \"ml-latest-small\"\n",
    "    name = \"ratings.csv\"\n",
    "    ratings_df = pd.read_csv(train_dpet + os.path.sep + name, names= [\"UserID\", \"MovieID\", \"Rating\", \"Timestamp\"], header=0)\n",
    "    ratings_df[\"UserID\"] = pd.to_numeric(ratings_df[\"UserID\"], errors='ignore')\n",
    "    ratings_df[\"MovieID\"] = pd.to_numeric(ratings_df[\"MovieID\"], errors='ignore')\n",
    "    ratings_df[\"Rating\"] = pd.to_numeric(ratings_df[\"Rating\"], errors='ignore')\n",
    "    ratings_df[\"Timestamp\"] = pd.to_numeric(ratings_df[\"Timestamp\"], errors='ignore')\n",
    "    R_df = ratings_df.pivot(index = 'UserID', columns ='MovieID', values = 'Rating').fillna(0)  \n",
    "    R = R_df.as_matrix()\n",
    "    user_ratings_mean = np.mean(R, axis = 1)\n",
    "    R_demeaned = R - user_ratings_mean.reshape(-1, 1)\n",
    "    TRAIN_SIZE = 0.80\n",
    "    train_ratings = R_demeaned[:100]\n",
    "    test_ratings = R_demeaned[100:120]\n",
    "    test_r = np.array(test_ratings)\n",
    "    train_r = np.array(train_ratings)\n",
    "    num_neighbours = 1\n",
    "    r_range = 10 * 0.3\n",
    "    train_dp = train_r\n",
    "    test_dp = test_r\n",
    "    print(\"1\")\n",
    "    lsh_test(train_dp, test_dp, r_range, num_neighbours, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We compute the precision and recall of the top-T items for T ∈ {1, 5, 10}, obtained from the sorted list\n",
    "based on M atches. To compute this precision and recall, we start at the top of the ranked item list and walk\n",
    "down in order. Suppose we are at the kth ranked item, we check if this item belongs to the gold standard top-T list. If it is one of the top-T gold standard item, then we increment the count of relevant seen by 1,\n",
    "else we move to k + 1. By kth step, we have already seen k items, so the total items seen is k. The precision and recall at that point is then computed as: Precision =(relevant seen/k); Recall = (relevant seen/T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
